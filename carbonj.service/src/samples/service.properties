#
# Copyright (c) 2018, salesforce.com, inc.
# All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause
# For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause
#
#

# CarbonJ Beta Config
#

# Stack Identification
dw.groupId=carbonj
dw.podId=98
dw.groupFormat=.*

#
# Jetty Port
#

# Port to listen for rpc traffic on
# Line Protocol Channel : jetty.port + 2
# Pickle Protocol Channel : jetty.port + 3
jetty.port=2001

#
# Self Metric Destination
#
graphite.host=relay-udp.carbonj.svc.cluster.local
graphite.port=2003
graphite.transport=UDP
# CBAYER: I haven't found any evidence that this setting is honored by codahale/dropwizard lib 4.0 that we use. Neither
# is it referenced in our code.
graphite.transport.tcp.reconnect=true

#
# Aggregation
#
aggregation.enabled=true

#
# Metrics Store Config
#
metrics.store.enabled=true
metrics.store.lowerResolutionArchives.enabled=true
metrics.store.dataDir=work/carbonj-data
metrics.store.stagingDir=work/carbonj-staging
metrics.store.stagingIntervalsQueueConsumersPerDb=4
metrics.store.stagingIntervalQueueConsumerBatchSize=30000

metrics.tasks.queueSize=500000
metrics.tasks.queueReadBatchSize=10000

#
# Max Query Restriction
#

# request for 10000 metrics over 500 days
metrics.store.maxDataPointsPerRequest=240000000

# request for 10000 metrics over a day
metrics.store.heavyQueryThreshold=14400000

#
# Caches
#
metrics.store.nameIndexCacheSize=12000000
metrics.store.expireAfterWriteQueryCacheInSeconds=300
string.cache.maxSize=13000000

# Sort Dir
staging.systemSort.tmpDir=work/carbonj-tmp

# to support import
#jetty.maxFormContentSize=1000000

metrics.store.fetchSeriesThreads=50
metrics.store.threadBlockingQueueSize=100

metrics.store.heavyQueryThreads=5
metrics.store.heavyQueryBlockingQueueSize=10

metrics.store.batchedSeriesSize=200

#
# Relay Options
#
relay.queue.rejectPolicy=block
relay.queue=3000000
relay.threads=3

#
# Debug
#
#debug.dumpIndex=true
#debug.dumpIndexFile=/data/carbonj/index-dump.out

#
# RocksDB Write Buffer
# 64m, 265m, 512m
#
#rocksdb.writeBufferSize=67108864
rocksdb.writeBufferSize=268435456
#rocksdb.writeBufferSize=536870912

rocksdb.maxWriteBufferNumber=4
rocksdb.minWriteBufferNumberToMerge=1

#
# RocksDB Tuning
#
# https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide
# https://github.com/facebook/rocksdb/wiki/Write-Stalls

#
# Level 0
#
# L0 file size =  writeBufferSize * minWriteBufferNumberToMerge = 256MB
# L0 stable size = writeBufferSize * minWriteBufferNumberToMerge * levelZeroFileNumCompactionTrigger = 256MB
rocksdb.levelZeroFileNumCompactionTrigger=1
rocksdb.levelZeroSlowDownWriteTrigger=8
rocksdb.levelZeroStopWritesTrigger=10
#rocksdb.increaseParallelism=

# Compactions
rocksdb.maxBackgroundCompactions=48
rocksdb.compactionThreadPoolSize=48

# 100MB Target file size in L1. Recommended value: maxBytesForLevelBase / 10
rocksdb.maxBytesForLevelBase=268435456
#rocksdb.maxBytesForLevelBase=1073741824

rocksdb.targetFileSizeBase=26843545
#rocksdb.targetFileSizeBase=536870912
#rocksdb.targetFileSizeBase=134217728

rocksdb.numLevels=5
rocksdb.targetFileSizeMultiplier=10
#rocksdb.maxBytesForLevelMultiplier=20
#rocksdb.blockSize=8192
# disable dup point detection on CJ. Relay does all the work.
pointFilter.dupPointCacheMaxSize=0

# to enable kinesis consumers
#kinesis.consumer.enabled=true

kinesis.kcl.prefix.default=umon-dev

events.kinesis.stream=umon-dev-logging

